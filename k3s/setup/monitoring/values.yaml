prometheusOperator: #(1.48m / 32.3) cpu/memory
  admissionWebhooks:
    enabled: false
    patch:
      enabled: false
  tls:
    enabled: false
  nodeSelector:
    role: worker
  resources:
    requests:
      cpu: 2m
      memory: 30Mi
    # limits:
    #   cpu: 6m
    #   memory: 64Mi

kube-state-metrics: #(0.49m / 24.0) cpu/memory
  nodeSelector:
    role: worker
  resources:
    requests:
      cpu: 1m
      memory: 25Mi
    # limits:
    #   cpu: 3m
    #   memory: 50Mi

alertmanager: #(0.23m / 19.8) cpu/memory
  enabled: true
  config:
    global:
      resolve_timeout: 5m
      # 1. [추가] 슬랙 웹훅 URL을 여기에 넣으세요
      slack_api_url: "https://hooks.slack.com/services/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"

    # (이 부분은 시끄러운 알람을 막아주는 좋은 규칙이니 그대로 둡니다)
    inhibit_rules:
      - source_matchers: [ 'severity = critical' ]
        target_matchers: [ 'severity =~ warning|info' ]
        equal: [ 'namespace', 'alertname' ]
      - source_matchers: [ 'severity = warning' ]
        target_matchers: [ 'severity = info' ]
        equal: [ 'namespace', 'alertname' ]
      - source_matchers: [ 'alertname = InfoInhibitor' ]
        target_matchers: [ 'severity = info' ]
        equal: [ 'namespace' ]

    route:
      group_by: ['namespace']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      
      # 2. [변경] 기본 수신자를 'null' -> 'slack-notifications'로 변경
      receiver: 'slack-notifications'
      
      routes:
      # 3. [테스트용 변경] 원래 Watchdog을 null로 버리는데, 
      # 테스트를 위해 잠시 주석 처리하거나 receiver를 slack으로 바꿉니다.
      - matchers:
          - alertname = "Watchdog"
        receiver: 'slack-notifications' # 테스트 끝나면 'null'로 바꾸세요

    receivers:
    - name: 'null'
    
    # 4. [추가] 슬랙 수신자 상세 설정 정의
    - name: 'slack-notifications'
      slack_configs:
      - channel: '#error' # 채널명 확인!
        send_resolved: true
        title: '[{{ .Status | toUpper }}] {{ .CommonLabels.alertname }}'
        text: >-
          *Description:* {{ .CommonAnnotations.description }}

          *Severity:* {{ .CommonLabels.severity }}
          
    templates:
    - '/etc/alertmanager/config/*.tmpl'

  alertmanagerSpec:
    nodeSelector:
      role: worker
    resources:
     requests:
       cpu: 1m
       memory: 20Mi
    #  limits:
    #    cpu: 3m
    #    memory: 40Mi
nodeExporter:
  enabled: false
# prometheus-node-exporter: # 마스터 노드에도 배포
#   tolerations:
#     - operator: Exists

prometheus:
  prometheusSpec:
    enableFeatures:
      - remote-write-receiver
    enableRemoteWriteReceiver: true
    nodeSelector:
      role: worker
    scrapeInterval: "1m" # 스크랩 간격을 1분
    retention: "15d" # 데이터 보존 기간을 10일
    retentionSize: "10GiB"
    resources: #(18.2m / 414) cpu/memory
      requests:
        cpu: 60m
        memory: 360Mi
      # limits:
      #   cpu: 120m
      #   memory: 800Mi

    # storageSpec:
    #   volumeClaimTemplate:
    #     spec:
    #       storageClassName: local-path
    #       accessModes: ["ReadWriteOnce"]
    #       resources:
    #         requests:
    #           storage: 15Gi # 저장 용량을 15Gi

grafana:
  nodeSelector:
    role: worker
  defaultDashboardsTimezone: KST
  adminPassword: "qwer1234!" # Grafana 관리자 비밀번호 설정
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"
      searchNamespace: ALL
    datasources:
      enabled: true
      defaultDatasourceEnabled: false
  additionalDataSources:
    - name: Prometheus
      type: prometheus
      uid: prometheus
      access: proxy
      url: http://kube-prometheus-stack-prometheus.monitoring:9090
      isDefault: true
    - name: Alertmanager
      type: alertmanager
      uid: alertmanager
      access: proxy
      url: http://kube-prometheus-stack-alertmanager.monitoring:9093
      jsonData:
        implementation: prometheus
    - name: Tempo
      type: tempo
      uid: tempo-v2
      access: proxy
      url: http://tempo.tracing:3200
      jsonData:
        serviceMap:
          datasourceUid: 'prometheus'
        nodeGraph:
          enabled: true
    - name: Loki
      type: loki
      uid: loki
      access: proxy
      url: http://loki.logging:3100
  resources: # (3.30m / 141) cpu/memory -> 메모리 변경 폭이 큼
    requests:
      cpu: 10m  #수정
      memory: 140Mi
    # limits:
    #   cpu: 30m #수정
    #   memory: 280Mi

kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false
kubeEtcd:
  enabled: false